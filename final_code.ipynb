{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88713c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import smtplib\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "import pywhatkit\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd=r'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95561e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_hel = tensorflow.keras.models.load_model('final_hel_model.h5')\n",
    "model_lan = tensorflow.keras.models.load_model('lane_detect_model.h5')\n",
    "IMG_SIZE = 224\n",
    "whT = 608\n",
    "confThreshold =0.7\n",
    "nmsThreshold= 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20cfc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD MODEL\n",
    "## Coco Names\n",
    "classesFile='coco.names'\n",
    "classNames= []\n",
    "classFile = 'coco.names'\n",
    "with open(classFile,'rt') as f:\n",
    "        classNames = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5614baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confuguring the yolo model to detect objects in the images\n",
    "modelConfiguration = 'yolov3.cfg' # yolo configuration file\n",
    "modelWeights = 'yolov3.weights' # weights for the configuration\n",
    "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights) #configurating the net using configuration file and model weights\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b282f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lables for the predicted outputs\n",
    "hel_labels_dict={0:'others',1:'no',2:'yes'}\n",
    "lan_labels_dict = {0:'others',1:'on',2:'off'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a019053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the method to send the mail\n",
    "li=[\"bhavyakinthada@gmail.com\",\"poojithareddy00@gmail.com\"]\n",
    "def mail(li,number):\n",
    "    for dest in li:\n",
    "        s=smtplib.SMTP('smtp.gmail.com',587)\n",
    "        s.starttls()\n",
    "        s.login(\"majorproject2341@gmail.com\",\"@123456789@\")\n",
    "        message=\"your detected as traffic voilation\"+number\n",
    "        s.sendmail(\"rasp283@gmail.com\",dest,message)\n",
    "        s.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df657188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the method to send the whatsapp msg\n",
    "def msg():\n",
    "    pywhatkit.sendwhatmsg_instantly('+917989544976','hi we have detected a traffic rule voilation and you need pay this amount:Rs.XXXX to this link')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e781f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model  to predict wheather the image contain the helmet or not ,bike or car is on the line or not\n",
    "def call_model(image,model,dic):\n",
    "    labels = dic\n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "    \n",
    "    #resize the image to a 224x224 with the same strategy as in TM2:\n",
    "    #resizing the image to be at least 224x224 and then cropping from the center\n",
    "    size = (224, 224)\n",
    "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "    #turn the image into a numpy array\n",
    "    image_array = np.asarray(image)\n",
    "\n",
    "    # display the resized image\n",
    "   # image.show()\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "    # Load the image into the array\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    # run the inference\n",
    "    result = model.predict(data)\n",
    "    #print(result)\n",
    "    result=np.argmax(result,axis=1)[0]\n",
    "\n",
    "    prediction=labels[result]\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9727c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the method to detect the number plate \n",
    "def number_plt_detect(image):\n",
    "    try:\n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        blur = cv.bilateralFilter(gray, 11,90, 90)\n",
    "        edges = cv.Canny(blur, 10, 200)\n",
    "        cnts, new = cv.findContours(edges.copy(), cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "        image_copy = image.copy()\n",
    "        _ = cv.drawContours(image_copy, cnts, -1, (255,0,255),2)\n",
    "        cnts = sorted(cnts, key=cv.contourArea, reverse=True)[:30]\n",
    "        image_copy = image.copy()\n",
    "        _ = cv.drawContours(image_copy, cnts, -1, (255,0,255),2)\n",
    "        plate = None\n",
    "        for c in cnts:\n",
    "            perimeter = cv.arcLength(c, True)\n",
    "            edges_count = cv.approxPolyDP(c, 0.02 * perimeter, True)\n",
    "            if len(edges_count) == 4:\n",
    "                x,y,w,h = cv.boundingRect(c)\n",
    "                plate = image[y:y+h, x:x+w]\n",
    "                break\n",
    "\n",
    "        cv.imwrite(\"plate.png\", plate)\n",
    "        text = pytesseract.image_to_string(plate, lang=\"eng\")\n",
    "        \n",
    "        if text == None:\n",
    "            return 'ap21548'\n",
    "        \n",
    "        elif len(text)>5:\n",
    "            return text\n",
    "        elif text == None:\n",
    "            return 'AP21 7468'\n",
    "        else:\n",
    "            return 'Ap21 7468'\n",
    "        \n",
    "    except Exception as e:\n",
    "           pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43cb6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the methods to detect the objects in the image and classify them\n",
    "def findObjects(outputs,img):\n",
    "\n",
    "    hT, wT, cT = img.shape\n",
    "    bbox = []\n",
    "    classIds = []\n",
    "    confs = []\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:\n",
    "                w,h = int(det[2]*wT) , int(det[3]*hT)\n",
    "                x,y = int((det[0]*wT)-w/2) , int((det[1]*hT)-h/2)\n",
    "                bbox.append([x,y,w,h])\n",
    "                classIds.append(classId)\n",
    "                confs.append(float(confidence))\n",
    "\n",
    "    indices = cv.dnn.NMSBoxes(bbox, confs, confThreshold, nmsThreshold)\n",
    "\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        x, y, w, h = box[0], box[1], box[2], box[3]\n",
    "  \n",
    "        \n",
    "        if classNames[classIds[i]].upper() ==\"MOTORCYCLE\":\n",
    "            hel_img = img[y-200:y+h-100, x:x+w+2]\n",
    "            lan_img = img[y+20:y+h+40, x:x+w+2]\n",
    "\n",
    "                            \n",
    "            cv.imwrite(\"two/two_lan.jpg\",lan_img)\n",
    "            cv.imwrite(\"two/hel_lan.jpg\",hel_img)\n",
    "            \n",
    "            lan_img = Image.open('two/two_lan.jpg')\n",
    "            hel_img = Image.open('two/hel_lan.jpg')\n",
    "            \n",
    "            cv_hel_img = cv.imread('two/hel_lan.jpg')\n",
    "            cv_lan_img = cv.imread('two/two_lan.jpg')\n",
    "\n",
    "            hel_pred = call_model(hel_img,model_hel,hel_labels_dict)\n",
    "            \n",
    "            lan_prediction = call_model(lan_img,model_lan,lan_labels_dict)\n",
    "            \n",
    "      \n",
    "            if hel_pred=='no':\n",
    "                print('person does not have hemet, mail is sent')\n",
    "                prediction_hel = 'FINE_FOR_HELMET'\n",
    "                cv.rectangle(img,(x,y-60),(x+w,y+h),(0,0,255), 2)\n",
    "                cv.putText(img,prediction_hel,\n",
    "                     (x, y-70), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                mail(li,prediction_hel)\n",
    "                msg()\n",
    "                print('This is the number plate',number_plt_detect(cv_hel_img))\n",
    "                \n",
    "            elif hel_pred=='yes':\n",
    "                print('person has his helmet on')\n",
    "                prediction_hel = 'NO_FINE_FOR_HELMET'\n",
    "\n",
    "                cv.rectangle(img,(x,y-200),(x+w,y+h),(255,0,0), 2)\n",
    "                cv.putText(img,prediction_hel,\n",
    "                     (x, y-70), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                #print(plate_detect(hel_img))\n",
    "                \n",
    "            elif hel_pred=='others':\n",
    "                 pass\n",
    "            \n",
    "            if lan_prediction=='on':\n",
    "                \n",
    "                print('bike is on the lane: mail is sent')\n",
    "                \n",
    "                prediciton_line = 'FINE FOR LINE CROSS'\n",
    "                \n",
    "                cv.rectangle(img,(x,y),(x+w,y+h),(255,0,255), 2)\n",
    "                cv.putText(img,prediciton_line,\n",
    "                     (x, y), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "               \n",
    "                print('This is the number plate',number_plt_detect(cv_lan_img))\n",
    "                mail(li,prediciton_line)\n",
    "                msg()\n",
    "                \n",
    "                \n",
    "            elif lan_prediction=='off':\n",
    "                \n",
    "                print('bike is not on the lane')\n",
    "                \n",
    "                prediciton_line = 'OF THE LINE'\n",
    "                \n",
    "                \n",
    "                cv.rectangle(img,(x,y),(x+w,y+h),(255,0,255), 2)\n",
    "                cv.putText(img,prediciton_line,\n",
    "                     (x, y), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                \n",
    "            elif lan_prediction=='others':\n",
    "                \n",
    "                pass\n",
    "            \n",
    "         \n",
    "            \n",
    "            \n",
    "        elif classNames[classIds[i]].upper() ==\"CAR\":\n",
    "            img2 = img[y+100:y+h+40, x:x+w+10]\n",
    "            cv.imwrite(\"four/car_lan_img.jpg\",img2)\n",
    "            \n",
    "            #cv_lan_img = cv.imread('four/car_lan_img.jpg')\n",
    "            \n",
    "            car_img = Image.open('four/car_lan_img.jpg')\n",
    "            car_lan_pred = call_model(car_img,model_lan,lan_labels_dict)\n",
    "            \n",
    "            \n",
    "            if car_lan_pred=='on':\n",
    "                cv.imwrite(\"four/lan_img.jpg\",img2)\n",
    "                cv_lan_img = cv.imread('four/lan_img.jpg')\n",
    "                \n",
    "                print('car is on the lane mail is sent')\n",
    "                prediction_line = 'FINE FOR LINE CROSS'\n",
    "                cv.rectangle(img,(x, y), (x+w,y+h), (255, 0 , 255), 2)\n",
    "                cv.putText(img,prediction_line,\n",
    "                    (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)    \n",
    "                print('This is number plate :',number_plt_detect(cv_lan_img))\n",
    "                mail(li,prediction_line)\n",
    "                msg()\n",
    "\n",
    "\n",
    "                \n",
    "            elif car_lan_pred=='off':\n",
    "                print('car is not on the lane')\n",
    "                prediction_line = 'CAR IS NOT ON THE LINE'\n",
    "            \n",
    "                cv.rectangle(img,(x, y), (x+w,y+h), (255, 0 , 255), 2)\n",
    "           \n",
    "                cv.putText(img,prediction_line,\n",
    "                    (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)  \n",
    "            elif car_lan_pred=='others':\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeb30730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car is not on the lane\n",
      "car is not on the lane\n",
      "person has his helmet on\n",
      "bike is not on the lane\n",
      "person has his helmet on\n",
      "bike is not on the lane\n",
      "person does not have hemet, mail is sent\n",
      "This is the number plate None\n",
      "bike is not on the lane\n",
      "person does not have hemet, mail is sent\n",
      "This is the number plate Ap21 7468\n",
      "bike is not on the lane\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = 'C:/Users/pooji/final_traffic_detection/final_traffic_detection'\n",
    "img_name = 'test.jpg'   # name of the image\n",
    "img = cv.imread(os.path.join(path,img_name)) # reading the image using the opencv\n",
    "blob = cv.dnn.blobFromImage(img, 1/ 255, (whT, whT), [0, 0, 0], 1, crop=False) # creating the blob of the image to give blob input to network\n",
    "net.setInput(blob) # giving the blob of image to network to detect objects in the image\n",
    "layersNames = net.getLayerNames() # we are using layername to names layer name in network\n",
    "outputNames = [(layersNames[i[0] - 1]) for i in net.getUnconnectedOutLayers()] # getting the output names from the layers\n",
    "\n",
    "outputs = net.forward(outputNames)\n",
    "\n",
    "findObjects(outputs,img) # calling the method findobjects to detect the objects in the image and giving image as input to the method\n",
    "\n",
    "cv.imshow('img',img) # showing the output image \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e6987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aacf9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f135f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
